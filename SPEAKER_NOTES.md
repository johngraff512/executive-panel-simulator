# Speaker Notes
## AI Executive Panel Simulator Presentation

**For**: McCombs Instructional Innovation Group
**Duration**: 30 minutes (20 min presentation + 10 min demo)

---

## Pre-Presentation Checklist

**Technical Preparation** (1 hour before):
- [ ] Test simulator on presentation computer
- [ ] Upload test PDF (158-page Kohl's report works well)
- [ ] Configure executive panel (suggest: CEO, CFO, CMO for demo)
- [ ] Screenshot backup slides in case live demo fails
- [ ] Test internet connection
- [ ] Close unnecessary browser tabs/applications
- [ ] Set browser to full screen mode
- [ ] Have backup laptop ready

**Demo Setup**:
- [ ] Pre-configure session to Step 4 (ready to analyze)
- [ ] Have second browser tab ready with completed session summary
- [ ] Bookmark simulator URL for quick access
- [ ] Test TTS audio volume (if using)

**Materials**:
- [ ] Presentation slides loaded
- [ ] This speaker notes document
- [ ] Business cards or contact info to share
- [ ] Handout with simulator URL (optional)

---

## Slide-by-Slide Speaker Notes

### Slide 1: Title Slide
**Time**: 30 seconds

**What to Say**:
"Good morning/afternoon! I'm excited to share with you a tool we've developed to transform how students prepare for strategic management presentations. The AI Executive Panel Simulator gives students unlimited access to realistic executive questioning—something that traditionally hasn't scaled beyond one or two live panel sessions per semester."

**Delivery Tips**:
- Start with energy and enthusiasm
- Make eye contact with the group
- Briefly introduce yourself if needed
- Set expectations: "We'll cover the challenge, our solution, how it works, then do a live demo"

---

### Slide 2: The Challenge
**Time**: 1 minute

**What to Say**:
"In Strategic Management courses, we require students to present business plans and defend their strategic recommendations to simulated executive panels. This is incredibly valuable—it teaches them to think on their feet, defend their analyses, and communicate complex ideas clearly.

But here's the problem: live executive panels are expensive, time-consuming to coordinate, and they don't scale. Most students get maybe one or two practice opportunities before their high-stakes presentation. That's just not enough repetitions to build real confidence and skill.

Meanwhile, peer feedback—while valuable—lacks the executive-level scrutiny students need. And we can't provide 24/7 instructor Q&A sessions."

**Delivery Tips**:
- Acknowledge that live panels are great (don't dismiss traditional methods)
- Emphasize the scaling challenge
- Pause after "That's just not enough repetitions" for emphasis
- Connect with any instructors in the room: "I'm sure you've faced this challenge too"

**Anticipated Questions**:
- Q: "How many practice opportunities do students currently get?"
- A: "Typically 1-2 live panel sessions per semester, depending on class size and resources"

---

### Slide 3: Traditional Approaches & Limitations
**Time**: 1 minute

**What to Say**:
"Let's look at what we currently have available. Live executive panels are the gold standard—authentic, rigorous, with real expertise. But they're expensive and don't scale. We can maybe do one or two per semester.

Peer review is accessible and collaborative, but students lack the executive perspective and business experience to ask the tough questions executives would ask.

Instructor feedback is expert-driven, but incredibly time-intensive and still doesn't provide that 24/7 on-demand access students need.

And self-practice—well, it's convenient, but without challenge or feedback, students don't know if they're actually prepared."

**Delivery Tips**:
- Use the table to walk through each option systematically
- Don't spend too long here—this is setup for the solution
- Emphasize the gap: "realistic, rigorous, on-demand practice"

---

### Slide 4: Our Solution
**Time**: 1.5 minutes

**What to Say**:
"So we built the AI Executive Panel Simulator. Here's what it does differently:

First, it analyzes the complete student business plan—not just text, but tables, charts, and images. We're using GPT-4 Vision to actually understand their financial projections and visual data.

Second, it generates questions that target their specific strategic recommendations. This isn't a generic chatbot asking 'tell me about your market strategy.' Instead, it reads their actual proposal and challenges their specific choices.

Third, it simulates five distinct executive personas—CEO, CFO, CTO, CMO, COO—each with their own expertise and questioning style.

And most importantly, it's available 24/7. Students can practice as many times as they need, whenever they're ready.

Here's a sample question: [Read the quote slowly for emphasis] 'You're projecting 40% market share in year two, but what's your plan if competitors drop prices by 30%?'

Notice how that references their specific projection—40% market share—and challenges their assumptions about competitive response."

**Delivery Tips**:
- Read the example question with executive gravitas
- Pause after the question to let it sink in
- This is a key slide—don't rush it
- Emphasize "specific" multiple times

---

### Slide 5: Student Value Proposition
**Time**: 1 minute

**What to Say**:
"From the student perspective, there are four major benefits:

Realistic Practice: They face tough questions about their actual recommendations, in a safe environment where mistakes are learning opportunities, not grade penalties.

24/7 Availability: They practice when they're ready—maybe that's 2am the night before because that's when they finally finished their business plan. No scheduling required.

Comprehensive Analysis: The AI actually reads their entire report. We've tested it with 150-page documents. It understands their specific industry context, their financial projections, their charts and graphs.

And Learning Through Challenge: This isn't about giving them easy questions. It's about identifying gaps in their analysis, exposing weak assumptions, and pushing them to think deeper about strategic implications—before they get to the actual presentation."

**Delivery Tips**:
- Use the icons as visual anchors
- Emphasize "safe environment"—this is practice, not evaluation
- The "2am" example often resonates with instructors who remember their own student days

---

### Slide 6: Educational Alignment
**Time**: 1.5 minutes

**What to Say**:
"Let's talk about the pedagogical benefits—because this isn't just a cool tech demo, it's designed to support specific learning outcomes.

For students, they practice strategic communication skills, learn to defend recommendations with evidence rather than gut feel, develop confidence before high-stakes moments, identify weak spots early when they can still fix them, and master proper strategic management terminology.

For us as instructors, this is a scalable solution that works whether you have 30 students or 300. It ensures consistent, rigorous questioning across all students—no favoritism, no variability based on which executives showed up that day. It supplements live presentations by giving students that crucial practice time. It encourages deeper strategic thinking because students know they'll be challenged. And importantly, it frees our time for higher-value interactions—we're not spending office hours running practice Q&A sessions.

The learning outcomes this supports are exactly what we care about in Strategic Management: strategic reasoning and critical thinking, professional communication under pressure, data-driven decision defense, and assumption recognition and testing."

**Delivery Tips**:
- Connect to familiar pedagogical frameworks
- Emphasize that this supplements, not replaces, instructor interaction
- If time allows, ask: "What learning outcomes would this support in your courses?"

---

### Slide 7: How It Works - Student Journey
**Time**: 1 minute

**What to Say**:
"Let me walk you through the student experience. It's a simple 4-step process:

Step 1: They upload their business plan—drag and drop, up to 50MB, which handles even lengthy strategic analyses. We've also built in preset panel configurations for common scenarios.

Step 2: They provide company context—the name, industry, and report type. This sets the context for personalized questions.

Step 3: They select their executive panel. Maybe they want all five executives for a comprehensive review, or maybe just the CEO and CFO to focus on strategy and finance. Each executive has a distinct persona with their own expertise.

Step 4: They launch the panel session. The AI analyzes their report—this takes about 1 to 3 minutes—and then the executives start asking questions. Students respond in real-time, just like they would in an actual panel."

**Delivery Tips**:
- Keep this high-level; details come in next slides
- Use hand gestures to indicate the flow: upload → configure → launch
- Preview that you'll show this live in the demo

---

### Slide 8: How It Works - AI Analysis
**Time**: 1.5 minutes

**What to Say**:
"Behind the scenes, there's a lot happening during that 1-3 minute analysis window. We use what we call a hybrid parsing system:

First, PyMuPDF extracts all the text from every page. We don't truncate—we read the complete document. In our test case with a 158-page business plan, that was over 165,000 characters of text.

Second, pdfplumber identifies and extracts tables—financial projections, competitive matrices, data grids. In that same test document, it found 496 tables.

Third, and this is where it gets interesting, we use OpenAI's GPT-4o Vision API to analyze the top 10 charts, graphs, and diagrams. It doesn't just see pixels—it understands what the chart shows, extracts the data points, identifies trends, and understands the business context.

Finally, GPT-4 Turbo does the strategic extraction. It identifies the specific recommendations the student is proposing, the key analyses they performed, and the critical assumptions underlying their strategy. These become the foundation for the questions."

**Delivery Tips**:
- Don't get too technical unless audience is very technical
- The "496 tables" number often impresses people
- Emphasize the Vision API capability—many people don't know AI can "read" charts
- If asked about costs, mention it's about $2-5 per student per semester

**Anticipated Questions**:
- Q: "What if the student's PDF has poor formatting?"
- A: "The hybrid approach is robust. Even if tables don't extract perfectly, we still get text content and visual analysis"

---

### Slide 9: How It Works - Question Generation
**Time**: 1 minute

**What to Say**:
"This slide shows the difference between our approach and a traditional AI chatbot.

A generic chatbot would ask: 'What's your market strategy?' or 'How will you acquire customers?'—broad, generic questions that could apply to any business.

Our system asks: 'You're projecting 40% market share in year two, but what's your plan if competitors drop prices by 30%?'

Notice the difference? It references the actual number from their report—40% market share—and challenges a specific assumption they made about competitive dynamics.

Or: 'Your customer acquisition cost analysis assumes organic growth, but how will you actually reach enterprise customers without a sales team?'

It's identifying a gap between their assumption—organic growth—and the reality of their target market—enterprise customers who typically require a sales team.

This is what makes the practice valuable. Students have to defend their specific strategic choices with data and logic, not just talk about strategy in the abstract."

**Delivery Tips**:
- Read the example questions slowly and with gravitas
- Emphasize "specific" and "actual"
- This is a key differentiator—spend time here
- Ask: "Can you see how this is more challenging than generic questions?"

---

### Slide 10: The Five Executive Personas
**Time**: 2 minutes

**What to Say**:
"We've created five distinct executive personas, each based on real C-suite roles and responsibilities:

Sarah Chen, our CEO, focuses on strategic vision, competitive advantage, and long-term growth. Her style is visionary and direct, occasionally challenging. She might ask: 'How does this create sustainable competitive advantage?'

Michael Rodriguez, the CFO, is all about financial viability and ROI. He's analytical, data-driven, and frankly, skeptical. He'll ask: 'What's your plan if revenue comes in 30% below projections?'

Dr. Lisa Kincaid, the CTO, focuses on technical feasibility and scalability. She's detailed, technical, forward-thinking. She's asking: 'What technical risks could derail this implementation?'

James Thompson, our CMO, cares about market positioning and customer acquisition. He's creative, customer-focused, enthusiastic. His questions center on: 'How will customers perceive this against existing alternatives?'

And Rebecca Johnson, the COO, is all about operations and execution. She's practical, process-focused, results-oriented. She's asking: 'Do you have the operational capabilities to execute this at scale?'

The beauty is that students can choose which executives to include based on what they want to focus on. All five for comprehensive review, or maybe just CEO and CFO if they want to zero in on strategy and finance."

**Delivery Tips**:
- Use the emoji/icon to make each persona memorable
- Vary your tone when reading example questions (sound analytical for CFO, enthusiastic for CMO, etc.)
- This often gets positive reactions—lean into it
- If short on time, cover CEO, CFO, and one other in detail

---

### Slide 11: Key Features - Modern Interface
**Time**: 1 minute

**What to Say**:
"Version 2.0, which we just completed, features a completely redesigned interface.

We've moved to a wizard-based setup with clear visual progress tracking, so students always know where they are in the process.

During the panel session, the active executive is visually highlighted—you'll see this in the demo—with professional headshots and smooth animations. This helps students track who's asking what.

The conversation interface tracks the full history of questions and responses with clear visual distinction between the executives and the student.

And the session analytics at the end give students a summary of what was covered, with options to retry with different executive combinations or start fresh with a new company."

**Delivery Tips**:
- Keep this brief—they'll see it in the demo
- Emphasize the "professional" polish
- This shows you take UX seriously, not just AI functionality

---

### Slide 12: Key Features - Advanced Capabilities
**Time**: 1.5 minutes

**What to Say**:
"Beyond the core functionality, we've built in some advanced capabilities:

Optional web research: If enabled, the system uses the Tavily API to gather real-time company and market context—recent news, competitive moves, industry trends. This makes questions even more relevant. Instead of just 'what's your competitive advantage,' it might ask 'given that your main competitor just launched a similar product, how does that affect your differentiation strategy?'

Intelligent follow-ups: The AI analyzes student responses for completeness. If an answer is vague or raises new concerns, it generates clarifying questions. This creates a more natural conversation flow.

Text-to-speech: Students can enable voice for executive questions. We've tried to match voices to each personality. It's optional, but some students find it increases immersion and realism.

And strategic terminology alignment: This was important. We teach students that 'strategy' is singular—it's the integrated set of choices defining how you compete. 'Strategic initiatives' are the specific programs and actions. The AI now enforces this proper terminology, aligning with our course pedagogy."

**Delivery Tips**:
- The web research feature often surprises people—emphasize how it makes questions current
- The terminology alignment shows you care about disciplinary standards, not just tech
- If running short on time, hit web research and move on

---

### Slide 13: Demo Preparation
**Time**: 30 seconds

**What to Say**:
"Alright, let me show you this in action. I'm going to walk through the complete student workflow in about 10 minutes.

We'll start with uploading a sample business plan—I'm using a 158-page strategic analysis. Then configure the executive panel, wait briefly for the AI analysis, and launch a panel session where you'll see 2-3 challenging questions.

Finally, we'll complete the session and see the summary analytics.

This is the same experience a student would have, just condensed to fit our time."

**Delivery Tips**:
- Transition smoothly to demo mode
- Check that your demo setup is ready
- Take a breath and slow down—demos can make people rush

---

### Slide 14: [DEMO SLIDE]
**Time**: 10 minutes

**Demo Flow**:

**Part 1: Upload & Setup (2 min)**
1. Navigate to simulator homepage
   - "Here's what a student sees when they first access the simulator"
2. Show Step 1 with presets
   - "Notice the preset configurations—these are quick-start templates"
3. Upload PDF (if not pre-uploaded)
   - "I'm uploading a 158-page strategic analysis for Kohl's"
4. Click through to Step 2
   - Fill in company name: "Kohl's"
   - Industry: "Retail"
   - Report type: "Business Plan"
   - "This gives context for personalized questions"
5. Advance to Step 3
   - "Now the student selects their executive panel"
   - Click to select CEO, CFO, CMO
   - "Notice how the cards highlight when selected"
   - Hover over one to show effect
6. Advance to Step 4
   - "Here's the review screen"
   - Point out the toggles: "Web research is enabled, follow-ups are enabled"
   - "Question limit is 10 for a full session, but I'll do fewer for the demo"

**Part 2: Analysis (1 min)**
7. Click "Analyze Report and Launch Panel"
   - "Now the AI is processing all 158 pages"
   - Show the "Analyzing your report..." screen
   - "This normally takes 1-3 minutes. I've prepared one ahead of time to save us time"
   - [Switch to pre-analyzed session if needed]

**Part 3: Panel Session (5 min)**
8. Launch panel or show pre-launched session
   - "Here's the panel session screen"
   - Point out executive sidebar: "All executives are listed here"
   - Point out highlighted executive: "Notice the orange arrow and glow—that's the active executive"
9. Show first question
   - Read it aloud: "Listen to how specific this is..."
   - Point out how it references actual report content
   - "This isn't a generic question—it's challenging a specific assumption in the business plan"
10. Type a brief response
    - Don't spend too much time here
    - Example: "Our market research indicates strong brand loyalty among existing customers, which should provide insulation against price-based competition"
11. Submit and show next question
    - "Notice a different executive is now highlighted"
    - Read the new question
    - Point out how it targets a different aspect of the plan
12. Show conversation history
    - Scroll up to show previous Q&A
    - "Students can review all previous questions and their responses"

**Part 4: Summary (2 min)**
13. Complete session (or switch to completed session)
    - "Here's what students see when they finish"
14. Show session summary
    - Point out statistics: "Number of questions, which executives participated"
    - Show restart options: "Students can practice again with same company or start fresh"

**Delivery Tips**:
- Talk through what you're doing—don't let silent moments happen
- If technical glitches occur, use backup screenshots and keep narrating
- Read questions out loud for emphasis
- Point with your cursor to draw attention
- Check in: "Can everyone see this okay?" or "Questions so far?"

**Common Demo Issues & Fixes**:
- **Slow analysis**: Use pre-analyzed session
- **No internet**: Have screenshot backups ready
- **Questions not loading**: Refresh and use backup session
- **Typos in response**: Acknowledge with humor: "Students probably type better than I do under pressure"

---

### Slide 15: Technical Architecture
**Time**: 1 minute (only if technical audience)

**What to Say**:
"For those interested in the technical architecture, we built this on Flask with Python for the backend, using Gunicorn for production serving.

The AI models are all OpenAI: GPT-4 Turbo for question generation and analysis, GPT-4o Vision for chart and image analysis, and TTS-1 for text-to-speech.

We use PyMuPDF and pdfplumber for comprehensive PDF processing, and SQLite for session persistence.

The frontend is modern JavaScript with Tailwind CSS for styling. We're deployed on Heroku, making it globally accessible.

In terms of performance, we can analyze 150+ page documents in 1-3 minutes, handle concurrent student sessions, and we've built in intelligent truncation to stay under API token limits for very large documents."

**Delivery Tips**:
- Gauge audience interest—skip or abbreviate if not technical
- Don't get bogged down in details unless asked
- Focus on "it scales" and "it's reliable"

**Anticipated Questions**:
- Q: "Why Heroku instead of AWS?"
- A: "Simplicity and cost for initial deployment. We could move to AWS for larger scale"
- Q: "What about data privacy?"
- A: "We use temporary file processing with automatic cleanup. See backup slide on privacy."

---

### Slide 16: Implementation & Adoption
**Time**: 1 minute

**What to Say**:
"From an implementation perspective, this is designed to be easy for instructors to adopt.

You can share a web link—no installation required. Students just need internet access and their PDF. You can embed it in Canvas or your LMS. Or assign it as homework or a practice tool.

For student onboarding, we've created a 5-minute orientation video and a written guide with screenshots. No technical skills required.

In terms of recommended use cases: we suggest assigning it 1-2 weeks before their actual presentation as practice homework. Some instructors have students submit their session summary as proof of completion. It's great for competition preparation—MBA case competitions, pitch contests. It supplements office hours—students can practice on their own time. And it's valuable as a self-directed learning tool for students who want extra preparation.

Resource requirements are minimal: you need an OpenAI API key, a hosting platform like Heroku, and students need internet access and their PDF."

**Delivery Tips**:
- Emphasize "easy to adopt"
- Connect to their existing workflows (Canvas, homework assignments)
- Address the "how would I use this" question proactively

---

### Slide 17: Early Results & Student Feedback
**Time**: 1.5 minutes

**What to Say**:
"We're still in pilot phase, so these are informal observations rather than rigorous research data—though we'd love to partner on formal assessment.

We're seeing improvements in student confidence. Students report feeling more prepared for live panels, reduced anxiety about defending strategic choices, and improved ability to think on their feet.

The quality of questions they anticipate and prepare for has increased. They're coming to presentations with better preparation of supporting data and evidence, and more thorough analysis of their assumptions.

And we're seeing deeper strategic thinking. Students are considering alternative scenarios more carefully, recognizing weak spots in their analysis before submission, and better integrating strategy concepts from the course.

Here's a quote from a recent student: 'I thought my analysis was solid until the CFO asked about my revenue assumptions. It made me go back and really justify my projections with data. That preparation saved me during the actual presentation.'

That's exactly what we're going for—students identifying and fixing issues during practice, not during the graded presentation."

**Delivery Tips**:
- Be honest about pilot stage—this builds credibility
- The student quote is powerful—pause after reading it
- Emphasize the "aha moments" students have
- If you have more testimonials, share them

**Anticipated Questions**:
- Q: "How many students have used it?"
- A: "We've had [X] students across [Y] sections in pilot. We're planning a larger rollout for Spring 2026"
- Q: "What's the completion rate?"
- A: "Among students who start a session, [X]% complete it. Average is [Y] practice sessions per student"

---

### Slide 18: Comparison to Alternatives
**Time**: 1 minute

**What to Say**:
"This table shows why we think the AI Executive Simulator fills a unique niche.

Live executive panels score highest on realism, but they don't scale, they're expensive, and availability is limited.

Peer review scales great and is free, but lacks executive-level realism and the questions aren't personalized to the specific business plan.

Instructor Q&A is high-quality but doesn't scale and has limited availability.

Generic AI chatbots like ChatGPT scale well and are available 24/7, but they're not document-aware. They ask generic questions that could apply to any business.

Our AI Executive Simulator combines the scalability and availability of AI with the personalization and realism of live panels. It's document-aware, persona-driven, and pedagogically aligned.

That's the unique value proposition: executive-level rigor, on-demand, at scale."

**Delivery Tips**:
- Use the table visually—point to each cell as you discuss
- The comparison to generic chatbots is important—differentiate clearly
- End with emphasis on "unique value proposition"

---

### Slide 19: Lessons Learned & Challenges
**Time**: 1.5 minutes

**What to Say**:
"Let me share some of the challenges we faced and how we addressed them. This might be useful if you're thinking about similar projects.

First, rate limiting. When students uploaded large documents—150+ pages—we exceeded OpenAI's token limits and got errors. We solved this with intelligent truncation: we take the first 40%, middle 20%, and last 40% of the document. This preserves comprehensive coverage while staying under the limits.

Second, question quality. Early versions asked generic questions—they weren't much better than what a student could get from ChatGPT. We redesigned the system to first extract specific recommendations and analyses, then target questions to those items. That's when we started seeing questions that referenced actual numbers and proposals.

Third, strategic terminology. The AI kept misusing 'strategies' plural to refer to tactical actions. We had to add explicit prompting to align with Strategic Management terminology standards. Now it properly uses 'strategy' for overall direction and 'strategic initiatives' for specific programs.

And fourth, user experience. The original single-form interface was overwhelming. Students saw everything at once and didn't know where to start. We redesigned it as a wizard with 4 clear steps, visual progress tracking, and that dramatically improved completion rates.

The point is: building this took iteration and refinement based on real student usage. That's ongoing."

**Delivery Tips**:
- This shows you're thoughtful about problems, not just hyping the tech
- The terminology issue resonates with faculty who care about disciplinary standards
- Acknowledge that it's a work in progress—invites collaboration

---

### Slide 20: Future Directions
**Time**: 1 minute

**What to Say**:
"Let me give you a peek at our roadmap.

Short-term—in the next 6 months—we're adding performance scoring to automatically assess response quality, session transcripts that students and instructors can receive via email, an instructor dashboard to track student usage and engagement, and enhanced mobile optimization.

Medium-term—6 to 12 months—we're exploring voice input so students can respond verbally instead of typing, video presentation analysis that evaluates delivery not just content, team sessions for group projects, deep LMS integration, and customizable rubrics that align with specific assignment criteria.

Long-term—beyond a year—we're thinking about custom executive personas that instructors can create, industry-specific knowledge bases for specialized expertise, multi-language support, and adaptive difficulty where questions adjust to student level.

The vision is to make this increasingly flexible and powerful while maintaining the core value: realistic executive questioning that challenges students to think strategically."

**Delivery Tips**:
- Don't get bogged down in every bullet—hit highlights
- Ask: "What features would be most valuable for your courses?"
- Invite feedback: "We're very open to feature requests"

---

### Slide 21: Research & Assessment Opportunities
**Time**: 1 minute (adjust based on audience interest)

**What to Say**:
"For those interested in educational research, this platform opens up some interesting questions:

Learning effectiveness: Does AI practice actually improve live presentation performance? What's the optimal number of practice sessions? How does this correlate with final grades?

Skill development: Which strategic thinking skills improve most? How does questioning style affect learning? Do students transfer these skills to other contexts?

Technology acceptance: What drives student adoption? How does perception of realism affect value? What barriers prevent usage?

And comparative studies: How does AI practice compare to peer practice or no practice? What's the impact of different executive configurations? What's the effect of optional features like web research?

The beauty is that we have rich data: session logs with all questions and responses, timestamps, usage patterns, question types and difficulty, response length and quality indicators.

We'd love to partner with instructors or educational researchers on formal assessment studies."

**Delivery Tips**:
- Tailor depth to audience (skip if not research-focused)
- Emphasize collaboration opportunity
- The data availability often surprises people

**Anticipated Questions**:
- Q: "Would this count as IRB research?"
- A: "If we're analyzing student data for publication, yes. We're happy to collaborate on IRB protocols"
- Q: "Can we access the session data?"
- A: "With appropriate permissions and anonymization, yes"

---

### Slide 22: Cost & Sustainability
**Time**: 1 minute

**What to Say**:
"Let's talk about costs, because I know that's a practical concern.

Development costs were in-house—we didn't outsource this, so no external costs.

For ongoing costs per semester, OpenAI API usage is about $2 to $5 per student per semester. That's based on 3-5 practice sessions of 10 questions each with 150-page reports. For a class of 100, that's about $200-500 per semester.

Hosting on Heroku is about $25-50 per month, so $100-200 per semester.

Total cost per student: about $4-7 per semester.

Compare that to live executive panels at $500-1000 per session for honoraria and coordination, textbooks at $200-300 per student, or simulation software licenses at $50-100 per student.

The sustainability model is strong: highly scalable with minimal marginal cost per additional student. Once it's running, adding students doesn't significantly increase costs."

**Delivery Tips**:
- Be transparent about costs—this builds trust
- The comparison to alternatives is powerful
- Emphasize scalability: "The cost doesn't double if class size doubles"

**Anticipated Questions**:
- Q: "Who pays for the API costs?"
- A: "Currently department/instructor. We're exploring options for student fees or central funding"
- Q: "What if OpenAI raises prices?"
- A: "We could switch to other LLMs (Anthropic, open-source models) if needed"

---

### Slide 23: Broader Applications
**Time**: 1 minute

**What to Say**:
"While we built this for Strategic Management, the platform could be adapted for other courses across McCombs.

In Finance: investment pitch presentations, analyst Q&A simulation, financial modeling defense.

In Marketing: campaign proposal presentations, brand strategy pitches, market research presentations.

In Entrepreneurship: investor pitch practice, accelerator application prep, board presentation simulation.

In Operations: process improvement proposals, vendor selection defense, operational strategy presentations.

In Leadership & Ethics: crisis communication scenarios, ethical decision defense, stakeholder management practice.

Really, any course that requires business plan presentations, capstone projects, or case competition preparation could benefit from this kind of simulated executive questioning.

The core capability—analyzing a student's proposal and generating challenging questions about their specific recommendations—transfers across disciplines."

**Delivery Tips**:
- Tailor examples to your audience (emphasize their areas)
- Ask: "Can you see applications in your courses?"
- This often sparks ideas and engagement

---

### Slide 24: Getting Involved
**Time**: 1 minute

**What to Say**:
"If you're interested in piloting this in your course, here's what we're offering for Spring 2026:

We have limited slots available for a pilot program. We'll provide full support and training, and we're asking for feedback to help us improve and contribute to educational research if you're interested.

What we provide: access to the hosted simulator, student orientation materials, an instructor training session, technical support throughout the semester, and usage analytics and reports.

What we need from you: a course section of any size, an assignment integration point—maybe as homework before presentations—help collecting student feedback, and permission to share anonymized usage data.

If you're interested, please contact me. My email is on this slide, and I'm happy to meet during office hours or set up a separate time to discuss how this could work in your specific course."

**Delivery Tips**:
- Make the ask clear but not pushy
- Emphasize "limited slots" to create some urgency
- Provide multiple contact methods
- Offer flexibility: "any size class"

---

### Slide 25: Key Takeaways
**Time**: 1 minute

**What to Say**:
"Let me wrap up with the key takeaways:

The challenge is that students need realistic practice defending strategic recommendations, but live executive panels don't scale.

Our solution is an AI-powered executive simulator that reads complete business plans and generates challenging, specific questions targeting actual strategic choices.

The innovation is that it's not a generic chatbot—it's document-aware, persona-driven, and pedagogically aligned with Strategic Management principles.

The impact is unlimited practice opportunities 24/7, consistent rigor across all students, scalability without additional resources, and building confidence and strategic thinking skills.

And the opportunity for you is to pilot this in your course, contribute to educational research if interested, and help refine an innovative teaching tool.

We think this represents the kind of AI application that actually enhances learning rather than shortcuts it. Students still do the thinking, the analysis, the defending—AI just makes the practice more accessible and realistic."

**Delivery Tips**:
- Use the slide structure to organize your summary
- End on the "enhances learning" note—this is important
- Pause before Q&A transition

---

### Slide 26: Q&A
**Time**: 2-5 minutes (adjust based on remaining time)

**What to Say**:
"Thank you for your time and attention. I'm happy to take questions about implementation, technical details, pedagogical considerations, research opportunities, or anything else.

And please don't hesitate to reach out after the presentation if you think of questions later or want to discuss potential use in your courses."

**Delivery Tips**:
- Repeat questions for the room before answering
- It's okay to say "I don't know, but let me find out and get back to you"
- Point to backup slides if relevant: "I have more detail on that in the backup slides"
- Take note of questions that come up multiple times—these are feature requests or documentation gaps

**Common Questions & Suggested Answers**:

**Q: "What prevents students from just typing nonsense to get through quickly?"**
A: "Nothing technical prevents it, but there's no incentive. This is practice, not graded. Students who don't engage seriously are only hurting themselves. We could add instructor review of session transcripts if needed."

**Q: "Could students share sessions and copy responses?"**
A: "They could, but every session has different questions because they're generated based on the specific business plan. Copying wouldn't help much. And again, this is practice, not assessment."

**Q: "What if students become too reliant on AI and can't perform without it?"**
A: "This is practice for the real thing—the live presentation. It's like using flashcards to study for an exam. The AI isn't available during their actual panel presentation, so this builds skills, not dependence."

**Q: "How do you handle students without access to technology?"**
A: "We recommend using this as an optional practice tool, not a required assignment. Or provide computer lab access. The tool is web-based, so any device with internet works."

**Q: "Could this be used for other institutions beyond McCombs?"**
A: "Absolutely. The platform is institution-agnostic. We'd be happy to explore licensing or collaboration."

**Q: "What about students gaming the system or prompt injection?"**
A: "Students could try to manipulate prompts, but they'd only be wasting their own practice time. There's no grade benefit to gaming it. We've also built in some safeguards against obvious prompt injection."

**Q: "How do you ensure AI doesn't hallucinate or give wrong feedback?"**
A: "The AI is asking questions, not providing answers or feedback. Questions are based on extracting content from their document. Hallucination risk is low because we're not generating facts, just challenging their proposals."

**Q: "Could this replace instructors?"**
A: "Absolutely not, and that's not the goal. This supplements instructor interaction by handling routine practice, freeing instructor time for higher-value guidance, complex feedback, and strategic coaching that AI can't do."

---

## Post-Presentation Actions

**Immediately After**:
- [ ] Thank organizers and audience
- [ ] Collect business cards or emails from interested instructors
- [ ] Make notes on questions you couldn't answer
- [ ] Note feature requests or ideas that came up

**Within 24 Hours**:
- [ ] Send follow-up email to interested instructors with:
  - Simulator URL
  - Link to documentation (FEATURES.md, VISUAL_OVERVIEW.md)
  - Your contact info
  - Next steps for pilot participation
- [ ] Research answers to questions you couldn't answer
- [ ] Update documentation based on feedback

**Within 1 Week**:
- [ ] Schedule individual meetings with pilot-interested instructors
- [ ] Create pilot program structure (timeline, expectations, support)
- [ ] Develop instructor training materials
- [ ] Set up feedback collection process

---

## Emergency Backup Plans

**If Demo Completely Fails**:
1. Have screenshot sequence ready
2. Narrate through screenshots as if live
3. Apologize briefly: "This is why we call it AI—'Artificially Inconsistent.' Let me show you screenshots of a typical session"
4. Keep energy up and move through quickly

**If Questions Are Hostile or Skeptical**:
1. Stay calm and professional
2. Acknowledge concerns: "That's a valid concern..."
3. Provide evidence or offer to follow up: "Let me show you data on that" or "I don't have that data here, but I can get it to you"
4. Reframe to benefits: "The question is whether the benefits outweigh the risks, and here's what we're seeing..."

**If You Run Over Time**:
1. Check with organizer/audience: "I'm happy to continue if people have time, or we can wrap up"
2. Skip future slides and jump to Q&A
3. Offer to send slide deck for self-review
4. Make yourself available after for individual questions

**If Technical Issues with Screen Sharing**:
1. Email slides to organizer to present on their computer
2. Have printed handouts ready (if in-person)
3. Narrate without slides if necessary (use these speaker notes)

---

## Key Messages to Emphasize

**Throughout the presentation, reinforce these themes**:

1. **This supplements, not replaces, instruction**
   - AI handles routine practice
   - Instructors focus on high-value interactions
   - Human expertise remains central

2. **It's about practice, not assessment**
   - Safe environment for mistakes
   - Unlimited attempts
   - No grades attached to practice

3. **Document-aware questioning is the differentiator**
   - Not a generic chatbot
   - References specific proposals
   - Challenges actual assumptions

4. **Scalability without quality loss**
   - Consistent rigor across all students
   - Available 24/7
   - Minimal marginal cost

5. **Pedagogically aligned**
   - Supports specific learning outcomes
   - Aligns with course standards
   - Enhances strategic thinking

---

## Closing Thoughts

**Remember**:
- You're solving a real problem educators face
- You have working technology to demonstrate
- You're inviting collaboration, not selling
- Enthusiasm is contagious—show your excitement
- Listen as much as you present—their feedback improves the tool

**Good luck with your presentation!**

---

**Document Version**: 1.0
**Last Updated**: January 2026
**For**: McCombs Instructional Innovation Presentation
